<html>
<head>
    <script type="text/javascript">
    function decodeText() {
            sentence = document.getElementById("sentence").value
            url = "/decode?"+sentence;
            var xmlHttp = new XMLHttpRequest();
            xmlHttp.onreadystatechange = function() {
                if (xmlHttp.readyState == 4 && xmlHttp.status == 200)
                    document.getElementById("input_sentence").innerHTML = sentence
                    document.getElementById("output_sentence").innerHTML = xmlHttp.responseText
            }
            xmlHttp.open("GET", url, true); // true for asynchronous
            xmlHttp.send(null);
    }
    function onEnterPressed(e) {
        if (e.keyCode == 13) {
            decodeText();
        }
    }
    </script>
</head>

<body>
Comma Test.<br>
The model is ___MODEL_NAME___
<br>
<br>
Input: <div id="input_sentence"></div>
<br>
Output: <div id="output_sentence"></div>
<br>
   <input id="sentence" onkeypress="return onEnterPressed(event)" size="200" value="In this work we presented the Transformer, the first sequence transduction model based entirely on attention replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention" />
<br>
<input value="Submit" type="button" onclick="decodeText()" />
</body>

</html>
